##################################################################
#                    DSSG Team Cincinnati                        #
#                      Model Experiments                         #
##################################################################

# Temporal stuff
start_date: '01Jan2012'    #train only on inspections after this date
fake_today: '01Apr2014'
validation_window: '1Year'  # Or '1Month'

# Generate full parcel predictions for Cincinnati
# Turn on after model validation/evaluation is complete
prepare_field_test: False
inspection_date: '01Aug2015'

# only use residential parcels
residential_only: True

############################
# Feature selection        #
############################

#List features to use, follow the syntax table.column where column
#is used in a LIKE statement
#http://www.postgresql.org/docs/current/static/functions-matching.html
features:
    #- crime.%
    #- three11.%
    #- house_type.%
    - census_2010.rate_%

############################
# Model selection          #
############################

#See grid_values.py for supported models
#Use valid scikit-learn classes, provide the full path to the class
models:
 # - 'sklearn.ensemble.AdaBoostClassifier'
  - 'sklearn.ensemble.RandomForestClassifier'

#For each model you select, the pipeline will
#train a bunch of models, see grid_values for more
grid_size: 'small' #small, medium or big

############################
# Experiment name          #
############################

#The effecy of this will be different depending of which logger you are using
#in both case is optional. If you are using mongo, this will just simpy add a new
#key, this is useful for comments. If you are pickling results, this will be a prefix
#in your pkl files
experiment_name: 'testing'
