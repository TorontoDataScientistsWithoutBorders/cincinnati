{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cincinnati Blight: Retrain Models\n",
    "____"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import os\n",
    "\n",
    "# Config & database\n",
    "from sqlalchemy import create_engine\n",
    "import yaml\n",
    "import pymongo\n",
    "from pymongo import MongoClient\n",
    "\n",
    "from lib_cinci.train_and_predict import main, predict_on_date\n",
    "from lib_cinci import dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Configuration and DB connection\n",
    "from sklearn_evaluation.Logger import Logger\n",
    "\n",
    "folder = os.environ['ROOT_FOLDER']\n",
    "name = 'config.yaml'\n",
    "path = \"%s/%s\" % (folder, name)\n",
    "f = open(path, 'r')\n",
    "text = f.read()\n",
    "main = yaml.load(text)\n",
    "\n",
    "def load(name):\n",
    "    folder = os.environ['ROOT_FOLDER']\n",
    "    path = \"%s/%s\" % (folder, name)\n",
    "    with open(path, 'r') as f:\n",
    "        text = f.read()\n",
    "    dic = yaml.load(text)\n",
    "    return dic\n",
    "\n",
    "connparams = load('config.yaml')['db']\n",
    "uri = '{dialect}://{user}:{password}@{host}:{port}/{database}'.format(**connparams)\n",
    "libpq_uri = 'dbname={database} user={user} host={host} password={password} port={port}'.format(**connparams)\n",
    "\n",
    "\n",
    "engine = create_engine(uri)\n",
    "logger = Logger(host=main['logger']['uri'], db=main['logger']['db'], \n",
    "                collection=main['logger']['collection'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_groups = [18711, 1120, 14613, 5716, \n",
    "                27039, 7111, 28879, 26523, \n",
    "                1309, 12547, 10062, 28108, \n",
    "                11814, 7068, 29230, 25683, 7520]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "k = 7500 # top 5% of parcels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "models = pd.read_csv('model-results-grouped.csv')\n",
    "model_id_cols = [col for col in list(models) if col.startswith('model_id')]\n",
    "model_name_cols = [col for col in list(models) if col.startswith('name')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get neighborhood information to save with predictions\n",
    "parcel_info = pd.read_csv('parcels_with_neighborhood_31aug2016.csv', index_col='parcel_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_top_k = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for m in model_groups: \n",
    "\n",
    "    model_group = str(m)\n",
    "    model_id = str(models[model_id_cols].iloc[m].dropna().values[0])\n",
    "    \n",
    "    # Retrain model and get predictions on all parcels\n",
    "    trained_model_df, trained_model_dict = main(model_id=model_id, \n",
    "                                                train_end_date='30Aug2016',  \n",
    "                                                prediction_schema='features_31aug2016', \n",
    "                                                return_features=True, return_fitted=True)       \n",
    "    trained_model_df.sort_values('prediction', ascending=False, inplace=True)\n",
    "\n",
    "    # Add neighborhood metrics for each parcel and save to CSV\n",
    "    model_predictions = trained_model_df[['prediction']].join(parcel_info)\n",
    "    all_top_k[model_group] = model_predictions.head(7500)\n",
    "\n",
    "    # Save feature importances to CSV\n",
    "    feature_importances = pd.DataFrame(data = [trained_model_df.columns[:-1], \n",
    "                                               trained_model_dict['model'].feature_importances_]).T\n",
    "    feature_importances.columns = ['feature', 'feature_importance']\n",
    "    output_path = os.path.join('feature_importances', 'feature_importances_' + model_group + '.csv')\n",
    "    feature_importances.to_csv(output_path)\n",
    "    \n",
    "    # Get list of top k parcels below median ID\n",
    "    inspection_density_first_quartile = model_predictions['inspection_density'].quantile(0.25)\n",
    "    median_mask = model_predictions.inspection_density < inspection_density_median\n",
    "    below_median_ID = model_predictions[median_mask].head(k)\n",
    "    all_top_k[model_group + ' Below Median ID'] = below_median_ID\n",
    "\n",
    "    # Get list of top k parcels below first quartile ID\n",
    "    inspection_density_median = model_predictions.inspection_density.median()\n",
    "    first_quartile_mask = model_predictions.inspection_density < inspection_density_first_quartile\n",
    "    below_quartile_ID = model_predictions[first_quartile_mask].head(k)\n",
    "    all_top_k[model_group + ' Below First Quaritle ID'] = below_quartile_ID\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_top5 = pd.concat(top_k.values())\n",
    "all_top5['violations_per_house'] = all_top5['violation_rate'] * all_top5['inspection_density'] \n",
    "all_top5.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "all_top5.to_csv('all_top5.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make Feature Crosstabs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "query = '''\n",
    "        SELECT DISTINCT (table_name) \n",
    "        FROM information_schema.tables \n",
    "        WHERE table_schema = 'features_31aug2016';\n",
    "        '''\n",
    "all_tables = pd.read_sql(query, engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_features = {}\n",
    "\n",
    "for t in list(all_tables.table_name):\n",
    "\n",
    "    query = 'SELECT * FROM features_31aug2016.{table};'.format(table=t)\n",
    "    \n",
    "    features = pd.read_sql(query, engine, index_col = 'parcel_id')\n",
    "    features.columns = [t + '.' + str(col) for col in features.columns]\n",
    "    all_features[t] = features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_features = pd.concat(all_features.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_features_mean = all_features.mean(axis=0)\n",
    "all_features_mean = all_features_mean.append(pd.Series([1.0], index=['model_group']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_features_mean_df = all_features_mean.to_frame().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_averages = {}\n",
    "\n",
    "for m in model_groups: \n",
    "    list_name = str(m)\n",
    "    \n",
    "    model_features = all_features[all_features.index.isin(top_k[model_num].index)].mean(axis=0)\n",
    "    model_features = model_features.to_frame().T\n",
    "    \n",
    "    feature_averages[list_name + ' Top 5'] = model_features\n",
    "    feature_averages[list_name + ' Top 5']['model_group'] = model_num\n",
    "    feature_averages[list_name + ' Top 5']['subset'] = 'Top 5 Average'\n",
    "    feature_averages[list_name + ' Top 5']['list'] = 'All Parcels'\n",
    "    \n",
    "    feature_averages[list_name + ' Ratio'] = model_features.divide(all_features_mean_df, axis=1)\n",
    "    feature_averages[list_name + ' Ratio']['model_group'] = model_num\n",
    "    feature_averages[list_name + ' Ratio']['subset'] = 'Ratio'\n",
    "    feature_averages[list_name + ' Ratio']['list'] = 'All Parcels'\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "crosstabs = pd.concat(feature_averages.values())\n",
    "cts = crosstabs.append(all_features_mean_df)\n",
    "cts.set_index(['model_group','list','subset'], inplace=True)\n",
    "cts.reset_index(inplace=True)\n",
    "cts['new_index'] = cts['model_group'].map(int).map(str) + ' ' + cts['list'] + ' ' + cts['subset']\n",
    "cts.set_index('new_index', inplace=True)\n",
    "cts.T.to_csv('feature_crosstabs.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pairwise Overlap Between of top *k* Parcels Between Model Lists"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Compute the Jaccard matrix for all of the models. The *ij*th element of this matrix is the size of the intersection of the top *k* for models *i* and *j* divided by the size of their union. If models are sorting mostly the same parcels to the top *k*, then they are pretty equivalent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# From Joco batch_evaluator\n",
    "def compute_similarity(prediction_matrix, percent=True):\n",
    "        \"\"\" Given a matrix of individuals classified as positive from different\n",
    "        models, return a correlation-matrix-like matrix of jaccard similarities.\n",
    "        :param prediction_matrix: lists of top X indiviudals with highest risk\n",
    "                                  scores according to different models\n",
    "        :type prediction_matrix: pandas DataFrame \n",
    "        :returns: jaccard matrix\n",
    "        :rtype: pandas DataFrame\n",
    "        \"\"\"\n",
    "\n",
    "        jaccard_matrix = pd.DataFrame(index = prediction_matrix.columns.values,\n",
    "                                      columns = prediction_matrix.columns.values)\n",
    "        for col_a in prediction_matrix.columns:\n",
    "            position = prediction_matrix.columns.get_loc(col_a)\n",
    "            for col_b in prediction_matrix.ix[:,position:]:\n",
    "                intersection_cardinality = len(set.intersection(*[set(prediction_matrix[col_a]),\n",
    "                                               set(prediction_matrix[col_b])]))\n",
    "                \n",
    "                \n",
    "                if percent:\n",
    "                    jaccard = intersection_cardinality/float(k)\n",
    "                else:\n",
    "                    union_cardinality = len(set.union(*[set(prediction_matrix[col_a]),\n",
    "                                        set(prediction_matrix[col_b])]))\n",
    "                    jaccard = intersection_cardinality/float(union_cardinality)\n",
    "                \n",
    "                jaccard_matrix.loc[col_a, col_b] = jaccard\n",
    "                jaccard_matrix.loc[col_b, col_a] = jaccard\n",
    "\n",
    "        return(jaccard_matrix.astype(float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "top_k_keys = {10062: 'ID (10062)', \n",
    "              12547: 'ID (12547)',  \n",
    "              7111: 'ID (7111)',\n",
    "             28108: 'ID (28108)', \n",
    "             11814: 'ID (11814)',\n",
    "              18711: 'P@5 (18711)',\n",
    "              1120: 'P@5 (1120)',\n",
    "              14613: 'P@5 (14613)',\n",
    "              5716: 'P@5 (5716)',\n",
    "              7520: 'All 3 (7520)',\n",
    "              1309: 'All 3 (1309)',\n",
    "              26523: 'All 3 (26523)',\n",
    "              28879: 'All 3 (28879)',\n",
    "              27039: 'VR (27039)',\n",
    "              7068: 'VR (7068)',\n",
    "              29230: 'VR (29230)',\n",
    "              25683: 'VR (25683)'\n",
    "             }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d = {k: v.index.values for k,v in top_k.iteritems()}\n",
    "top_k_dict = {top_k_keys[k]: v for k, v in d.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prediction_matrix = pd.DataFrame.from_dict(top_k_dict)\n",
    "df = compute_similarity(prediction_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cmap = sns.cubehelix_palette(dark=0, light=1, start=.5, rot=-.75, as_cmap=True)\n",
    "\n",
    "f,ax = plt.subplots(figsize=(20, 15))\n",
    "\n",
    "ax = sns.heatmap(df,linewidths=0.5, vmin=0, vmax=1, cmap=cmap)\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "ax.figure.savefig('percent_similarity_top' + str(p) + '_' + date_tag)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
